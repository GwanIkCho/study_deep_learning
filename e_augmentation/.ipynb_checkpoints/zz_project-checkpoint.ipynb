{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637cfbdd-71fc-4f92-b25f-fd2368e0fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a529e0-b22a-4f45-9a79-89fd98297a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['appll', 'banana', 'cherry', 'chickoo', 'grapes', 'kiwi', 'mango', 'orange', 'strawberry']\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "root = './datasets/fruits/original'\n",
    "\n",
    "directories = glob(os.path.join(root, '*'))\n",
    "directory_names = []\n",
    "for directory in directories:\n",
    "    directory_names.append(directory[directory.rindex('\\\\') + 1:])\n",
    "\n",
    "print(directory_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90de754c-454c-4b7e-8d0e-6cfd5453984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 359 images belonging to 9 classes.\n",
      "{'appll': 0, 'banana': 1, 'cherry': 2, 'chickoo': 3, 'grapes': 4, 'kiwi': 5, 'mango': 6, 'orange': 7, 'strawberry': 8}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "root = './datasets/fruits/original'\n",
    "# root = './datasets/face/test/'\n",
    "image_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = image_data_generator.flow_from_directory(root, target_size=(244, 244), batch_size=32, class_mode='categorical')\n",
    "print(generator.class_indices)\n",
    "# generator_test = image_data_generator.flow_from_directory(root, target_size=(48, 48), batch_size=32, class_mode='categorical')\n",
    "# print(generator_test.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a170a4-959e-408f-87ca-ba0645133692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_paths</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/fruits/original\\appll\\Image_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./datasets/fruits/original\\appll\\Image_10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./datasets/fruits/original\\appll\\Image_11.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./datasets/fruits/original\\appll\\Image_12.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./datasets/fruits/original\\appll\\Image_13.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>./datasets/fruits/original\\strawberry\\Image_5.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>./datasets/fruits/original\\strawberry\\Image_6.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>./datasets/fruits/original\\strawberry\\Image_7.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>./datasets/fruits/original\\strawberry\\Image_8.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>./datasets/fruits/original\\strawberry\\Image_9.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file_paths  targets\n",
       "0         ./datasets/fruits/original\\appll\\Image_1.jpg        0\n",
       "1        ./datasets/fruits/original\\appll\\Image_10.jpg        0\n",
       "2        ./datasets/fruits/original\\appll\\Image_11.jpg        0\n",
       "3        ./datasets/fruits/original\\appll\\Image_12.jpg        0\n",
       "4        ./datasets/fruits/original\\appll\\Image_13.png        0\n",
       "..                                                 ...      ...\n",
       "354  ./datasets/fruits/original\\strawberry\\Image_5.jpg        8\n",
       "355  ./datasets/fruits/original\\strawberry\\Image_6.jpg        8\n",
       "356  ./datasets/fruits/original\\strawberry\\Image_7.jpg        8\n",
       "357  ./datasets/fruits/original\\strawberry\\Image_8.jpg        8\n",
       "358  ./datasets/fruits/original\\strawberry\\Image_9.jpg        8\n",
       "\n",
       "[359 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "f_df = pd.DataFrame({'file_paths': generator.filepaths, 'targets': generator.classes})\n",
    "f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7179014-b8fb-4415-9737-bfc6c93e14d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_paths</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/fruits/original/appll/Image_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./datasets/fruits/original/appll/Image_10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./datasets/fruits/original/appll/Image_11.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./datasets/fruits/original/appll/Image_12.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./datasets/fruits/original/appll/Image_13.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>./datasets/fruits/original/strawberry/Image_5.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>./datasets/fruits/original/strawberry/Image_6.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>./datasets/fruits/original/strawberry/Image_7.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>./datasets/fruits/original/strawberry/Image_8.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>./datasets/fruits/original/strawberry/Image_9.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file_paths  targets\n",
       "0         ./datasets/fruits/original/appll/Image_1.jpg        0\n",
       "1        ./datasets/fruits/original/appll/Image_10.jpg        0\n",
       "2        ./datasets/fruits/original/appll/Image_11.jpg        0\n",
       "3        ./datasets/fruits/original/appll/Image_12.jpg        0\n",
       "4        ./datasets/fruits/original/appll/Image_13.png        0\n",
       "..                                                 ...      ...\n",
       "354  ./datasets/fruits/original/strawberry/Image_5.jpg        8\n",
       "355  ./datasets/fruits/original/strawberry/Image_6.jpg        8\n",
       "356  ./datasets/fruits/original/strawberry/Image_7.jpg        8\n",
       "357  ./datasets/fruits/original/strawberry/Image_8.jpg        8\n",
       "358  ./datasets/fruits/original/strawberry/Image_9.jpg        8\n",
       "\n",
       "[359 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_df.loc[:, 'file_paths'] = f_df.file_paths.apply(lambda x: x.replace('\\\\', '/'))\n",
    "f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87aa0f2-079c-4577-aa7a-dc22cb118c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 359 images belonging to 9 classes.\n",
      "{'appll': 0, 'banana': 1, 'cherry': 2, 'chickoo': 3, 'grapes': 4, 'kiwi': 5, 'mango': 6, 'orange': 7, 'strawberry': 8}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "root = './datasets/fruits/original/'\n",
    "\n",
    "idg = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = idg.flow_from_directory(\n",
    "    root,\n",
    "    target_size=(244, 244),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c9739c4-5721-45d5-85f7-d577f09de4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(generator.filepaths[124]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def show_image(image):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    \n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db8a862f-7f7f-404d-af55-ca00be021ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets\n",
      "7    32\n",
      "1    32\n",
      "4    32\n",
      "2    32\n",
      "8    32\n",
      "5    32\n",
      "3    32\n",
      "0    32\n",
      "6    31\n",
      "Name: count, dtype: int64\n",
      "targets\n",
      "0    8\n",
      "6    8\n",
      "8    8\n",
      "2    8\n",
      "1    8\n",
      "3    8\n",
      "7    8\n",
      "5    8\n",
      "4    8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(f_df.file_paths, f_df.targets, stratify=f_df.targets, test_size=0.2, random_state=124)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe47e299-80e8-4f50-8ca6-939a918a1dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets\n",
      "0    26\n",
      "5    26\n",
      "3    26\n",
      "8    26\n",
      "7    25\n",
      "6    25\n",
      "2    25\n",
      "1    25\n",
      "4    25\n",
      "Name: count, dtype: int64\n",
      "targets\n",
      "7    7\n",
      "1    7\n",
      "2    7\n",
      "4    7\n",
      "0    6\n",
      "8    6\n",
      "3    6\n",
      "6    6\n",
      "5    6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "train_test_split(X_train, y_train, stratify=y_train, test_size=0.2, random_state=124)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f82ef13-967c-400e-8476-14df5a51617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "root = './datasets/fruits/'\n",
    "\n",
    "for file_path in X_train:\n",
    "    animal_dir = file_path[len(root + 'original/'): file_path.rindex('/')]\n",
    "    destination = os.path.join(root, 'train/' + animal_dir)\n",
    "\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "\n",
    "    shutil.copy2(file_path, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77beb909-33db-431b-ac8b-68456305b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "root = './datasets/fruits/'\n",
    "\n",
    "for file_path in X_val:\n",
    "    animal_dir = file_path[len(root + 'original/'): file_path.rindex('/')]\n",
    "    destination = os.path.join(root, 'validation/' + animal_dir)\n",
    "\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "\n",
    "    shutil.copy2(file_path, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3119325e-10ef-4979-adb9-90a8f1277903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "root = './datasets/fruits/'\n",
    "\n",
    "for file_path in X_test:\n",
    "    animal_dir = file_path[len(root + 'original/'): file_path.rindex('/')]\n",
    "    destination = os.path.join(root, 'test/' + animal_dir)\n",
    "\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "\n",
    "    shutil.copy2(file_path, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e51f75-bf7b-4d3d-a849-90ab0685400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "def transform(image):\n",
    "    aug = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.OneOf([\n",
    "            A.ColorJitter(p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5)\n",
    "        ], p=1)\n",
    "    ], p=0.5)\n",
    "    return aug(image=image)['image']\n",
    "\n",
    "\n",
    "# idg = ImageDataGenerator(preprocessing_function=transfrom, rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54804aec-c9fc-4a32-95e2-06b419127715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def albumentations_preprocessing_function(image):\n",
    "    image = image.astype(np.uint8)  # Ensure the image is in the right format\n",
    "    image = transform(image=image)\n",
    "    return image.astype(np.float16) / 255.0  # 이미지 타입을 float32로 변환하고 정규화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e4ed715-db28-452d-a95c-1b8058ca0d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 229 images belonging to 9 classes.\n",
      "Found 58 images belonging to 9 classes.\n",
      "Found 72 images belonging to 9 classes.\n",
      "{'appll': 0, 'banana': 1, 'cherry': 2, 'chickoo': 3, 'grapes': 4, 'kiwi': 5, 'mango': 6, 'orange': 7, 'strawberry': 8}\n",
      "{'appll': 0, 'banana': 1, 'cherry': 2, 'chickoo': 3, 'grapes': 4, 'kiwi': 5, 'mango': 6, 'orange': 7, 'strawberry': 8}\n",
      "{'appll': 0, 'banana': 1, 'cherry': 2, 'chickoo': 3, 'grapes': 4, 'kiwi': 5, 'mango': 6, 'orange': 7, 'strawberry': 8}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "train_dir = './datasets/fruits/train'\n",
    "validation_dir = './datasets/fruits/validation'\n",
    "test_dir = './datasets/fruits/test'\n",
    "\n",
    "train_data_generator = ImageDataGenerator(preprocessing_function=albumentations_preprocessing_function, rescale=1./255)\n",
    "validation_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_data_generator.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fd209a2-8eed-480a-ac7e-d93892ba594c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_27               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_28               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_29               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_30               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_31               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_32               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_33               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_34               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_35               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115200</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115200</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">34,560,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,709</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_27               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_27 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_28               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_28 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_29               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_29 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_30               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_30 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_31               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_31 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_32               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_32 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_33               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_33 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_34               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_34 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_35               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_35 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115200\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115200\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │      \u001b[38;5;34m34,560,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m2,709\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,046,465</span> (133.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,046,465\u001b[0m (133.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,045,121</span> (133.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,045,121\u001b[0m (133.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> (5.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,344\u001b[0m (5.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "# alpha를 크게 할 수록 Weight값을 작게 만들어서 과적합을 개선할 수 있고\n",
    "# alpha를 작게 할 수록 Weight의 값이 커지지만, 어느 정도 상쇄하므로 과소적합을 개선할 수 있다.\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same',kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(300, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee5fd550-02bf-4eaa-bfff-1e8079fa9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54b15bf7-b29f-4087-980b-1535965b5c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HANSUNG\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 5s/step - acc: 0.1337 - loss: 71.4694 - val_acc: 0.1379 - val_loss: 1696.9677 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 5s/step - acc: 0.2225 - loss: 28.4516 - val_acc: 0.1034 - val_loss: 5154.0439 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 5s/step - acc: 0.2437 - loss: 7.6410 - val_acc: 0.1034 - val_loss: 5546.5156 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 4s/step - acc: 0.2259 - loss: 5.8253"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      4\u001b[0m     train_generator,\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      6\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m      7\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m      8\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb]\n\u001b[0;32m      9\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42528474-f804-4dc2-a68e-71a2f6d7e108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_59               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_60               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_61               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_62               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_63               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">153,900</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,709</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_62 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_59               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_59 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_63 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_60               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_60 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_64 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_61               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_61 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_65 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_62               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_62 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_66 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_63               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_63 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │         \u001b[38;5;34m153,900\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m2,709\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,729,153</span> (6.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,729,153\u001b[0m (6.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,727,169</span> (6.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,727,169\u001b[0m (6.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "# alpha를 크게 할 수록 Weight값을 작게 만들어서 과적합을 개선할 수 있고\n",
    "# alpha를 작게 할 수록 Weight의 값이 커지지만, 어느 정도 상쇄하므로 과소적합을 개선할 수 있다.\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=3, padding='same',kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(300, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "465f44a7-b242-4c37-92ca-28396a277797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7043a7cf-3915-47af-baaf-90dfb885156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 78s/step - acc: 0.1632 - loss: 2.8611 - val_acc: 0.1034 - val_loss: 4.1736 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:05\u001b[0m 87s/step - acc: 0.2812 - loss: 2.1297"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      4\u001b[0m     train_generator,\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      6\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m      7\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m      8\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb]\n\u001b[0;32m      9\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c202d87-c329-40c5-a520-b1368f229111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">153,900</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,709</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │         \u001b[38;5;34m153,900\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m2,709\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,729,153</span> (6.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,729,153\u001b[0m (6.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,727,169</span> (6.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,727,169\u001b[0m (6.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "# alpha를 크게 할 수록 Weight값을 작게 만들어서 과적합을 개선할 수 있고\n",
    "# alpha를 작게 할 수록 Weight의 값이 커지지만, 어느 정도 상쇄하므로 과소적합을 개선할 수 있다.\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=3, padding='same',kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(300, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9519a411-3672-4801-9c2a-2932246ab13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HANSUNG\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 18s/step - acc: 0.1483 - loss: 3.0583 - val_acc: 0.1207 - val_loss: 4.1490 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m18s\u001b[0m 18s/step - acc: 0.1997 - loss: 2.3010"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e78d3b49-6f67-453e-a271-da951a2bfbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,709</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m19,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m2,709\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,985</span> (164.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,985\u001b[0m (164.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,793</span> (163.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,793\u001b[0m (163.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "# alpha를 크게 할 수록 Weight값을 작게 만들어서 과적합을 개선할 수 있고\n",
    "# alpha를 작게 할 수록 Weight의 값이 커지지만, 어느 정도 상쇄하므로 과소적합을 개선할 수 있다.\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same',kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(300, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4291afa5-84dd-4ac9-ab6f-8321ff20ca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HANSUNG\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - acc: 0.0693 - loss: 2.6281 - val_acc: 0.1379 - val_loss: 2.2385 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - acc: 0.0944 - loss: 2.4109 - val_acc: 0.1207 - val_loss: 2.3119 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - acc: 0.1636 - loss: 2.1726 - val_acc: 0.1207 - val_loss: 2.4033 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - acc: 0.1579 - loss: 2.1459 - val_acc: 0.1207 - val_loss: 2.4326 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 9s/step - acc: 0.0000e+00 - loss: 2.2224"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb]\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37630530-83ad-4fd1-8356-c0b17b5cfdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,373,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m2,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m51,264\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │       \u001b[38;5;34m7,373,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,428,889</span> (28.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,428,889\u001b[0m (28.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,428,697</span> (28.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,428,697\u001b[0m (28.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "# x = Conv2D(filters=64, kernel_size=5, strides=2, kernel_initializer='he_normal')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = MaxPooling2D(2)(x)\n",
    "\n",
    "\n",
    "# x = Conv2D(filters=128, kernel_size=5, strides=2, kernel_initializer='he_normal', padding='same')(input_tensor)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, strides=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1f79e71-a3ec-475b-8867-c0e92496477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - acc: 0.1148 - loss: 9.2197 - val_acc: 0.1207 - val_loss: 8.1155 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 992ms/step - acc: 0.1851 - loss: 6.3368 - val_acc: 0.2069 - val_loss: 2.5250 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 955ms/step - acc: 0.3367 - loss: 1.9166 - val_acc: 0.2759 - val_loss: 2.2097 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 880ms/step - acc: 0.3286 - loss: 1.8721 - val_acc: 0.2414 - val_loss: 3.2049 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 997ms/step - acc: 0.4262 - loss: 1.6961 - val_acc: 0.1724 - val_loss: 3.0719 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 917ms/step - acc: 0.4020 - loss: 1.5085 - val_acc: 0.1897 - val_loss: 3.0745 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - acc: 0.4701 - loss: 1.5273 - val_acc: 0.1724 - val_loss: 3.3126 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 939ms/step - acc: 0.4639 - loss: 1.5038 - val_acc: 0.1724 - val_loss: 3.5201 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 909ms/step - acc: 0.4919 - loss: 1.5374 - val_acc: 0.1724 - val_loss: 3.7449 - learning_rate: 1.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 463ms/step - acc: 0.4770 - loss: 1.4294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4549d205-98ab-4317-bfd4-2a370e48bc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,373,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m2,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m25,632\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m51,264\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m102,464\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_9 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │       \u001b[38;5;34m7,373,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,557,369</span> (28.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,557,369\u001b[0m (28.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,556,985</span> (28.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,556,985\u001b[0m (28.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "# x = Conv2D(filters=64, kernel_size=5, strides=2, kernel_initializer='he_normal')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = MaxPooling2D(2)(x)\n",
    "\n",
    "\n",
    "# x = Conv2D(filters=128, kernel_size=5, strides=2, kernel_initializer='he_normal', padding='same')(input_tensor)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, strides=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bca472d0-08f5-4904-9f09-29268aba7ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - acc: 0.1197 - loss: 11.6488 - val_acc: 0.1207 - val_loss: 32.1798 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - acc: 0.1950 - loss: 4.3036 - val_acc: 0.1379 - val_loss: 121.9279 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - acc: 0.2270 - loss: 2.8919 - val_acc: 0.1207 - val_loss: 71.2266 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3s/step - acc: 0.2355 - loss: 2.4007 - val_acc: 0.1207 - val_loss: 60.9719 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m2/8\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 2s/step - acc: 0.1641 - loss: 2.1176  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb]\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2139df5-bb45-4860-9658-ac95f17c56f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">819,456</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">147456</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">147456</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">29,491,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m2,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_14 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m51,264\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_15 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m204,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_16 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m819,456\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_17 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m147456\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m147456\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │      \u001b[38;5;34m29,491,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,573,209</span> (116.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,573,209\u001b[0m (116.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,572,249</span> (116.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,572,249\u001b[0m (116.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=5, strides=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c91186f1-503a-4fa2-9704-63b2c7511298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4s/step - acc: 0.1319 - loss: 31.6600 - val_acc: 0.1034 - val_loss: 261.0531 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4s/step - acc: 0.1959 - loss: 19.4283 - val_acc: 0.1207 - val_loss: 1258.6733 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - acc: 0.1969 - loss: 7.2177 - val_acc: 0.1207 - val_loss: 585.8478 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4s/step - acc: 0.2299 - loss: 2.9927 - val_acc: 0.1207 - val_loss: 500.9001 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - acc: 0.2929 - loss: 3.2055 - val_acc: 0.1207 - val_loss: 367.7422 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 4s/step - acc: 0.2839 - loss: 2.4108"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb]\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "787f1d1c-0869-4018-8740-ef3c4e105b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_35\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_35\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_50               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_51               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_52               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_53               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33856</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33856</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,771,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_50 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m2,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_50               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_50 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_51 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m25,632\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_51               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_51 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_52 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m51,264\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_52               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_52 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_53 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m102,464\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_53               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_53 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_16 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33856\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33856\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │       \u001b[38;5;34m6,771,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,955,769</span> (26.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,955,769\u001b[0m (26.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,955,385</span> (26.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,955,385\u001b[0m (26.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, strides=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1dd6040-96cf-4e11-9201-c54a857fcee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - acc: 0.1343 - loss: 8.0493 - val_acc: 0.1724 - val_loss: 6.2130 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - acc: 0.2566 - loss: 4.0359 - val_acc: 0.2069 - val_loss: 8.8512 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - acc: 0.3042 - loss: 2.0283 - val_acc: 0.1897 - val_loss: 5.3237 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step - acc: 0.2833 - loss: 1.9020 - val_acc: 0.1034 - val_loss: 8.8888 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - acc: 0.3088 - loss: 2.0270"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb]\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66c3dada-2035-45da-a11b-727ec3759505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_37\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_37\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_54               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_55               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_56               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73728</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73728</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">14,745,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_54 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m2,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_54               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_54 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_55 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m51,264\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_55               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_55 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_56 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m204,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_56               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_56 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_17 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73728\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73728\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │      \u001b[38;5;34m14,745,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,007,129</span> (57.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,007,129\u001b[0m (57.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,006,681</span> (57.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,006,681\u001b[0m (57.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=5, strides=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1d3bf7c-f12c-4b7d-b09b-30e52c573993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - acc: 0.1177 - loss: 24.2574 - val_acc: 0.1207 - val_loss: 41.7177 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - acc: 0.2087 - loss: 13.1817 - val_acc: 0.1207 - val_loss: 26.6147 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - acc: 0.2932 - loss: 3.9118 - val_acc: 0.1207 - val_loss: 2.7952 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - acc: 0.2329 - loss: 2.0669 - val_acc: 0.1552 - val_loss: 2.2582 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m3/8\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 3s/step - acc: 0.2309 - loss: 2.0569 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb]\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3814677c-901e-4e4b-8a05-2e41c71ce8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_39\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_39\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_57               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_58               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204800</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204800</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">40,960,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_19 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_57 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m2,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_57               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_57 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_58 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m102,528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_58               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_58 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_18 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m204800\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m204800\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │      \u001b[38;5;34m40,960,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,067,609</span> (156.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,067,609\u001b[0m (156.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,067,289</span> (156.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,067,289\u001b[0m (156.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=5, strides=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb7fd0ef-c97b-484a-81a0-4d1eeebc9441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - acc: 0.1873 - loss: 40.3804 - val_acc: 0.1897 - val_loss: 30.3458 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - acc: 0.2983 - loss: 13.1865 - val_acc: 0.1379 - val_loss: 19.6943 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - acc: 0.2428 - loss: 4.8568 - val_acc: 0.1034 - val_loss: 11.6166 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - acc: 0.2495 - loss: 2.1014 - val_acc: 0.1897 - val_loss: 4.5263 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - acc: 0.2870 - loss: 1.9719 - val_acc: 0.1207 - val_loss: 9.9737 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - acc: 0.2521 - loss: 2.1129 - val_acc: 0.1897 - val_loss: 2.2069 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - acc: 0.3591 - loss: 1.7528 - val_acc: 0.1552 - val_loss: 4.0361 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - acc: 0.3163 - loss: 1.9742 - val_acc: 0.1379 - val_loss: 3.4617 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - acc: 0.2954 - loss: 1.9223 - val_acc: 0.1552 - val_loss: 2.7048 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893ms/step - acc: 0.2789 - loss: 1.8001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6581053-da4e-4776-b54c-542682a31cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_41\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_41\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_59               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,832</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_60               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204800</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204800</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">40,960,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_20 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_59 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m1,216\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_59               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_59 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_60 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │          \u001b[38;5;34m12,832\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_60               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_60 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_19 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m204800\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m204800\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │      \u001b[38;5;34m40,960,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,976,249</span> (156.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,976,249\u001b[0m (156.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,976,153</span> (156.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,976,153\u001b[0m (156.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, strides=3, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "742f295a-8ce2-4dc6-bf70-821ee3427564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - acc: 0.1547 - loss: 43.0009 - val_acc: 0.1897 - val_loss: 33.2047 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 998ms/step - acc: 0.1655 - loss: 10.7562 - val_acc: 0.1207 - val_loss: 4.1954 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - acc: 0.2660 - loss: 2.1649 - val_acc: 0.0862 - val_loss: 2.1735 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - acc: 0.1288 - loss: 2.1724 - val_acc: 0.1034 - val_loss: 2.1911 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 994ms/step - acc: 0.1362 - loss: 2.1998 - val_acc: 0.1034 - val_loss: 2.1973 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 624ms/step - acc: 0.1151 - loss: 2.2039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34c4d961-1c0a-4aae-a7c6-353eaf7cf457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_45\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_45\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_64               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,832</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_65               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_66               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204800</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204800</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">40,960,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_64 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m1,216\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_64               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_64 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_65 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m12,832\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_65               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_65 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_66 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │          \u001b[38;5;34m25,632\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_66               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_66 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_21 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m204800\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m204800\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │      \u001b[38;5;34m40,960,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,002,009</span> (156.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,002,009\u001b[0m (156.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,001,849</span> (156.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,001,849\u001b[0m (156.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, strides=3, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a1eed02-e494-4a4d-8d8b-50eebd90fd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - acc: 0.1102 - loss: 42.2959 - val_acc: 0.0690 - val_loss: 20.7646 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - acc: 0.1907 - loss: 24.9532 - val_acc: 0.1207 - val_loss: 10.2619 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - acc: 0.1888 - loss: 5.4005 - val_acc: 0.1034 - val_loss: 3.3145 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - acc: 0.1312 - loss: 2.3479 - val_acc: 0.1034 - val_loss: 2.1972 - learning_rate: 0.0010\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb]\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fa7dfc3-21d3-49c1-aa16-27be1b912381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_47\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_47\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_68               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_69               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_70               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">819,456</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_71               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_72               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73728</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73728</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">14,745,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_68 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m2,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_68               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_68 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_69 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m51,264\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_69               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_69 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_70 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m204,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_70               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_70 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_71 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m819,456\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_71               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_71 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_72 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m3,277,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_72               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_72 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_22 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73728\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73728\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │      \u001b[38;5;34m14,745,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,106,969</span> (72.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,106,969\u001b[0m (72.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,104,985</span> (72.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,104,985\u001b[0m (72.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=5, strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=5,strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=5, strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1bac2aa-262a-4a97-90a1-e32cecf8fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - acc: 0.1101 - loss: 15.2944 - val_acc: 0.0862 - val_loss: 240.1295 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - acc: 0.1204 - loss: 9.2999 - val_acc: 0.1552 - val_loss: 27.9987 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - acc: 0.1261 - loss: 5.3395 - val_acc: 0.1552 - val_loss: 16.8560 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - acc: 0.1271 - loss: 2.8908 - val_acc: 0.1207 - val_loss: 4.1020 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - acc: 0.0862 - loss: 2.1462 - val_acc: 0.1207 - val_loss: 2.5335 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m3/8\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 3s/step - acc: 0.1076 - loss: 2.0892 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb]\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9cc9fc0e-a0d3-4585-b1dc-f9d2125b49a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_53\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_53\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_83               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_84               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_85               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">819,456</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_86               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_87               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_26 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_83 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m2,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_83               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_83 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_84 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m51,264\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_84               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_84 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_85 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m204,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_85               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_85 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_86 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m819,456\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_86               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_86 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_87 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m3,277,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_87               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_87 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │         \u001b[38;5;34m102,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,463,769</span> (17.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,463,769\u001b[0m (17.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,461,785</span> (17.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,461,785\u001b[0m (17.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=5, strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=5,strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=5, strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de36ef2-7369-4509-8150-80a4572d58be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4bd73843-a7c7-49e9-ac24-3005ba07ed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 11s/step - acc: 0.1607 - loss: 2.4995 - val_acc: 0.1552 - val_loss: 16.8124 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 10s/step - acc: 0.3539 - loss: 1.8971 - val_acc: 0.1552 - val_loss: 21.3808 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 11s/step - acc: 0.2368 - loss: 2.1107 - val_acc: 0.1379 - val_loss: 22.1148 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 10s/step - acc: 0.3515 - loss: 1.8092 - val_acc: 0.1034 - val_loss: 15.7112 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 18s/step - acc: 0.1562 - loss: 2.2983"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb]\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11f1f74d-eb97-4588-b71c-771b3d5077aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_55\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_55\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,864</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_88               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_89               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">819,456</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_90               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_91               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">909</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_27 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_88 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m4,864\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_88               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_88 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_89 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m204,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_89               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_89 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m119\u001b[0m, \u001b[38;5;34m119\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_90 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m819,456\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_90               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_90 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_91 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m3,277,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_91               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_91 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_54 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m51,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │             \u001b[38;5;34m909\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,362,609</span> (16.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,362,609\u001b[0m (16.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,360,689</span> (16.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,360,689\u001b[0m (16.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=5, strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2, 1)(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=5,strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=5, strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(100, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12d46090-91d5-4677-a292-5b90d2bf9d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7s/step - acc: 0.1398 - loss: 2.5367 - val_acc: 0.1034 - val_loss: 17.1448 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 8s/step - acc: 0.2457 - loss: 2.0484 - val_acc: 0.1034 - val_loss: 20.4993 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 8s/step - acc: 0.2503 - loss: 2.0543 - val_acc: 0.1552 - val_loss: 22.1143 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 7s/step - acc: 0.3174 - loss: 1.9377 - val_acc: 0.1724 - val_loss: 17.6001 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - acc: 0.2859 - loss: 1.9533 - val_acc: 0.1552 - val_loss: 16.0930 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - acc: 0.2944 - loss: 1.8919 - val_acc: 0.1552 - val_loss: 14.9068 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - acc: 0.3191 - loss: 1.9174 - val_acc: 0.1552 - val_loss: 14.6640 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 8s/step - acc: 0.3717 - loss: 1.7599 - val_acc: 0.1552 - val_loss: 14.6553 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 8s/step - acc: 0.3527 - loss: 1.8318 - val_acc: 0.1552 - val_loss: 14.6951 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - acc: 0.4037 - loss: 1.6417 - val_acc: 0.1552 - val_loss: 16.2313 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - acc: 0.3195 - loss: 1.8345 - val_acc: 0.1379 - val_loss: 16.5659 - learning_rate: 1.0000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 7s/step - acc: 0.3673 - loss: 1.7160 - val_acc: 0.1379 - val_loss: 16.9924 - learning_rate: 1.0000e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 8s/step - acc: 0.3384 - loss: 1.7677"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb],\n\u001b[0;32m     14\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b19f5215-d3a7-4591-b28f-90a990599853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_67\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_67\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,864</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_110              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_111              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_112              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">409,728</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_113              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_114 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">819,456</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_114              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_114 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,638,656</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_115              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_116 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_116              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_116 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,554,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_117              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">909</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_33 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_110 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m4,864\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_110              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_110 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_111 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m102,464\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_111              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_111 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_112 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m204,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_112              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_112 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_113 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m409,728\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_113              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_113 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_114 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m819,456\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_114              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_114 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_115 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m1,638,656\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_115              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_115 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_23 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_116 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m3,277,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_116              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_116 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_117 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m6,554,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_117              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_117 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_66 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m51,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_67 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │             \u001b[38;5;34m909\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,071,409</span> (49.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,071,409\u001b[0m (49.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,067,569</span> (49.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,067,569\u001b[0m (49.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> (15.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,840\u001b[0m (15.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=5, strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2, 1)(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=5,strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=5,  kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=5, strides=2, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(100, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad2af756-fbbe-4724-a8da-7e196951ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 34s/step - acc: 0.2059 - loss: 2.5011 - val_acc: 0.1207 - val_loss: 1171.8777 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 37s/step - acc: 0.2889 - loss: 2.2645 - val_acc: 0.1207 - val_loss: 2667.4080 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 32s/step - acc: 0.3168 - loss: 2.0051 - val_acc: 0.1207 - val_loss: 1754.4480 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 33s/step - acc: 0.2063 - loss: 2.1147 - val_acc: 0.1207 - val_loss: 709.1898 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 33s/step - acc: 0.2070 - loss: 1.9921 - val_acc: 0.1207 - val_loss: 407.4960 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 33s/step - acc: 0.3212 - loss: 1.8856 - val_acc: 0.1207 - val_loss: 272.0712 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 33s/step - acc: 0.2977 - loss: 2.0309 - val_acc: 0.1207 - val_loss: 189.4484 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 33s/step - acc: 0.2183 - loss: 1.9924 - val_acc: 0.1207 - val_loss: 143.4322 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:58\u001b[0m 43s/step - acc: 0.2188 - loss: 2.1274"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb],\n\u001b[0;32m     14\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7f214c9-0dfd-4db7-87f9-a9e8dd07097e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_63\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_63\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_104              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_105              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">235</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">235</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">235</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">235</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_106              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">235</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">235</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">235</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">235</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_107              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,373,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_31 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_104 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m2,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_104              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_104 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_105 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m25,632\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_105              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_105 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m236\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_19 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m235\u001b[0m, \u001b[38;5;34m235\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_106 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m235\u001b[0m, \u001b[38;5;34m235\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m51,264\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_106              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m235\u001b[0m, \u001b[38;5;34m235\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_106 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m235\u001b[0m, \u001b[38;5;34m235\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_107 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m102,464\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_107              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_107 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_26 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │       \u001b[38;5;34m7,373,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,557,369</span> (28.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,557,369\u001b[0m (28.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,556,985</span> (28.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,556,985\u001b[0m (28.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2, 1)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, strides=5, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c2a14df-9256-4412-8669-b948600dc04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4s/step - acc: 0.0654 - loss: 13.9817 - val_acc: 0.1207 - val_loss: 15.6324 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4s/step - acc: 0.1998 - loss: 5.1814 - val_acc: 0.1207 - val_loss: 7.0077 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - acc: 0.2590 - loss: 2.3535 - val_acc: 0.1207 - val_loss: 8.2310 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5s/step - acc: 0.2748 - loss: 1.9403 - val_acc: 0.1207 - val_loss: 13.9124 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4s/step - acc: 0.3326 - loss: 1.9220 - val_acc: 0.1207 - val_loss: 11.7899 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 3s/step - acc: 0.2943 - loss: 2.0788"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb],\n\u001b[0;32m     14\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "afc21065-6068-4c6d-a3e6-c460e512ee69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_65\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_65\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_108              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">239</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">239</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_109              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">409600</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">409600</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">81,920,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,809</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_32 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_108 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m2,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_108              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_108 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m239\u001b[0m, \u001b[38;5;34m239\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_109 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m51,264\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_109              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_109 (\u001b[38;5;33mActivation\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_27 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m409600\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_64 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m409600\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │      \u001b[38;5;34m81,920,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_65 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_65 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m1,809\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,976,089</span> (312.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81,976,089\u001b[0m (312.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,975,897</span> (312.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81,975,897\u001b[0m (312.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=5, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2, 1)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=5, strides=3, kernel_initializer='he_normal', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(200, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(9, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "81b8a5e5-95f2-47a1-8b74-03506511f57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - acc: 0.1642 - loss: 61.0457 - val_acc: 0.0862 - val_loss: 33.5496 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - acc: 0.2240 - loss: 21.4701 - val_acc: 0.1207 - val_loss: 17.7231 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - acc: 0.2255 - loss: 2.6457 - val_acc: 0.1379 - val_loss: 5.5199 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - acc: 0.1924 - loss: 2.1240 - val_acc: 0.1207 - val_loss: 4.2622 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step - acc: 0.1454 - loss: 2.0963 - val_acc: 0.1207 - val_loss: 3.8707 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step - acc: 0.2084 - loss: 2.0424 - val_acc: 0.2241 - val_loss: 2.5754 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step - acc: 0.1622 - loss: 2.1266 - val_acc: 0.1207 - val_loss: 5.7219 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m3/8\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 2s/step - acc: 0.2118 - loss: 2.1593 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     train_generator,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     13\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb],\n\u001b[0;32m     14\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[mcp_cb, rlr_cb],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706fcbf-ca02-4a5e-806e-2001b478a282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a775a-d500-42b5-845f-035931d85ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
