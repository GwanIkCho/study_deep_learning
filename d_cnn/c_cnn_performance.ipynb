{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b34f8d3b-0559-485c-96ed-8485a31ffa58",
   "metadata": {},
   "source": [
    "### CNN Performance\r\n",
    "- CNN 모델을 제작할 때, 다양한 기법을 통해 성능 개선 및 과적합 개선이 가능하다.\r\n",
    "\r\n",
    "#### Weight Initialization, 가중치 초기화\r\n",
    "- 처음 가중치를 어떻게 줄 것인지를 정하는 방법이며, 처음 가중치를 어떻게 설정하느냐에 따라 모델의 성능이 크게 달라질 수 있다.\r\n",
    "  \r\n",
    "> 1. 사비에르 글로로트 초기화\r\n",
    "> - 고정된 표준편차를 사용하지 않고, 이전 층의 노드 수에 맞게 현재 층의 가중치를 초기화한다.\r\n",
    "> - 층마다 노드 개수를 다르게 설정하더라도 이에 맞게 가중치가 초기화되기 때문에 고정된 표준편차를 사용하는 것보다 이상치에 민감하지 않다.\r\n",
    "> - 활성화 함수가 ReLU일 때, 층이 지날 수록 활성화 값이 고르지 못하게 되는 문제가 생겨서, 출력층에서만 사용한다.\r\n",
    ">  \r\n",
    "> <div style=\"display: flex; margin-left: 50px;\">\r\n",
    "    <div>\r\n",
    "        <img src=\"./images/xavier01.png\">\r\n",
    "    </div>\r\n",
    "    <div>\r\n",
    "        <img src=\"./images/xavier02.png\" style=\"margin-left: 50px;\">\r\n",
    "    </div>\r\n",
    "</div>  \r\n",
    "\r\n",
    "> 2. 카이밍 히 초기화\r\n",
    "> - 고정된 표준편차를 사용하지 않고, 이전 층의 노드 수에 맞게 현재 층의 가중치를 초기화한다.\r\n",
    "> - 층마다 노드 개수를 다르게 설정하더라도 이에 맞게 가중치가 초기화되기 때문에 고정된 표준편차를 사용하는 것보다 이상치에 민감하지 않다.\r\n",
    "> - 활성화 함수가 ReLU일 때, 추천하는 초기화 방법으로서, 층이 깊어지더라도 모든 활성값이 고르게 분포된다.\r\n",
    "> <img src=\"./images/he.png\" style=\"margin-left: 50px;\">\r\n",
    "\r\n",
    "#### Batch Normalization, 배치 정규화\r\n",
    "- 입력 데이터 간에 값의 차이가 발생하면, 가중치의 비중도 달라지기 때문에 층을 통과할 수록 편차가 심해진다.  \r\n",
    "   이를 내부 공변량 이동(Internal Convariant Shift)이라고 한다.\r\n",
    "- 가중치의 값의 비중이 달라지면, 특정 가중치에 중점을 두면서 경사 하강법이 진행되기 때문에,  \r\n",
    "  모든 입력값을 표준 정규화하여 최적의 parameter를 보다 빠르게 학습할 수 있도록 해야한다.\r\n",
    "- 가중치를 초기화할 때 민감도를 감소시키고, 학습 속도 증가시키며, 모델을 일반화하기 위해서 사용한다.\r\n",
    "\r\n",
    "<div style=\"display: flex; width: 90%;\">\r\n",
    "    <div>\r\n",
    "        <img src=\"./images/BN01.png\" width=\"900\" style=\"margin-top: 20px;\">\r\n",
    "    </div>\r\n",
    "    <div>\r\n",
    "        <img src=\"./images/BN02.png\" width=\"900\">\r\n",
    "    </div>\r\n",
    "</div>\r\n",
    "\r\n",
    "- BN은 activation function 앞에 적용하면, weight 값은 평균이 0, 분산이 1인 상태로 정규분포가 된다.\r\n",
    "- ReLU가 activation으로 적용되면 음수에 해당하는(절반 정도) 부분이 0이 된다.  \r\n",
    "  이러한 문제를 해결하기 위해서 γ(감마)와 β(베타)를 사용해서 음수부분이 모두 0이 되는 것을 막아준다.\r\n",
    "\r\n",
    "<div style=\"display: flex; width: 70%;\">\r\n",
    "    <div>\r\n",
    "        <img src=\"./images/BN03.png\" width=\"1000\" style=\"margin-top: 20px;\">\r\n",
    "    </div>\r\n",
    "    <div>\r\n",
    "        <img src\n",
    "\n",
    "#### Batch Size\n",
    "- batch size를 작게 하면, 적절한 noise가 생겨서 overfitting을 방지하게 되고, 모델의 성능을 향상시키는 계기가 될 수 있지만, 너무 작아서는 안된다.\n",
    "- batch size를 너무 작게 하는 경우에는 batch당 sample 수가 작아져서 훈련 데이터를 학습하는 데에 부족할 수 있다.\n",
    "- 따라서 굉장히 크게 주는 것 보다는 작게 주는 것이 좋으며, 이를 또 너무 작게 주어서는 안된다.\n",
    "  논문에 따르면 8보다 크고 32보다 작게 주는 것이 효과적이라고 한다.\n",
    "\n",
    "<d<div style=\"display: flex; width: 70%;\">\r\n",
    "    <div>\r\n",
    "        <img src=\"./images/batch_size01.png\" width=\"800\" style=\"margin-top: 10px;\">\r\n",
    "    </div>\r\n",
    "    <div>\r\n",
    "        <img src=\"./images/batch_size02.png\" width=\"800\">\r\n",
    "    </div>\r\n",
    "\n",
    "#### Global Average Pooling\n",
    "- 이전의 Pooling들은 면적을 줄이기 위해 사용했지만, Global Average Pooling은 면적을 없애고 채널 수 만큼 값을 나오게 한다.\n",
    "- feature map의 가로 x 세로의 특정 영역을 Sub sampling하지 않고, 채널 별로 평균 앖을 추출한다.\n",
    "- feature map의 채널 수가 많을 경우(보통512개 이상) 이를 적용하고, 채널 수가 적다면 Flatten을 적용한다.\n",
    "- Flatten 후에 Classification Dense Layer로 이어지면서 많은 파라미터들로 인한 overfitting 유발 가능성 중대 및 학습 시간 증가로 이어지기 때문에\n",
    "  맨 아래 feature map의 채널 수가 크다면 Global Average Pooling을 적용하는 것이 더 나을 수 있다.\n",
    "\n",
    "<img src='./images/global_average_pooling.png' width='650px'>\n",
    "\n",
    "#### Weught Regularization (가중치 규제), Weight Dency (가중치 감소)\n",
    "- loss function은 loss값이 작아지는 방향으로 가중치를 update한다.\n",
    "- 하지만, loss를 줄이는 데에만 신경쓰게 되면, 특정 가중치가 너무 커지면서 오히려 나쁜 결과를 가져올 수 있다.\n",
    "- 기존 가중치에 특정 연산을 수행하여 loss function의 출력 값과 더해주면 loss function의 결과를 어느정도 제어할 수 있게 된다.\n",
    "- 보통 파라미터가 많은 Dense Layer에서 많이 사용되고 가중치가 규제보다는 loss function에 규제를 걸어 가중치를 감소시키는 원리이다.\n",
    "- kernel_regularizer 파라미터에서 l1, l2을 선택할 수 있다.\n",
    "\n",
    "<img src='./images/regularization.png' width='450px' >\n",
    "</div>\n",
    "#### Globak Average Pooling=\"./images/BN04.png\" width=\"800\">\r\n",
    "    </div>\r\n",
    "</div>le=\"margin-left: 50px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46312763-20f4-4377-9222-93fae03b3dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(train_images, train_targets), (test_images, test_targets) = cifar10.load_data()\n",
    "\n",
    "print(train_images.shape, train_targets.shape)\n",
    "print(test_images.shape, test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5c15a11-f9ff-4067-90fb-c8ec677dd6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,)\n",
      "(10000, 32, 32, 3) (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_targets = train_targets.squeeze()\n",
    "test_targets = test_targets.squeeze()\n",
    "\n",
    "print(train_images.shape, train_targets.shape)\n",
    "print(test_images.shape, test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9948b849-84db-4def-a995-258f0de652c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_perprocessed_data(images, targets):\n",
    "    images = np.array(images / 255.0, dtype=np.float32)\n",
    "    targets = np.array(targets, dtype=np.float32)\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ced233ee-1a07-4b0e-9192-eab799d4f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, Activation, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "INPUT_SIZE = 32\n",
    "\n",
    "input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 3))\n",
    "\n",
    "# alpha를 크게 할 수록 Weight값을 작게 만들어서 과적합을 개선할 수 있고\n",
    "# alpha를 작게 할 수록 Weight의 값이 커지지만, 어느 정도 상쇄하므로 과소적합을 개선할 수 있다.\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', kernel_regularizer=l2(1e-5), kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', kernel_regularizer=l2(1e-5), kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_regularizer=l2(1e-5), kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_regularizer=l2(1e-5), kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same', kernel_regularizer=l2(1e-5), kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same', kernel_regularizer=l2(1e-5), kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "X = Dropout(rate=0.5)(x)\n",
    "x = Dense(300, activation='relu', kernel_regularizer=l2(1e-5), kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(10, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c458d3e-35d7-4a04-8318-db25d7c3fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c379331a-fa9e-496e-b4c9-b346fd7affb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 117ms/step - acc: 0.4345 - loss: 1.5761 - val_acc: 0.6520 - val_loss: 1.0043 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m 622/1250\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 109ms/step - acc: 0.6619 - loss: 0.9856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# model = create_model()\n",
    "# model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath='./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only = False,\n",
    "    save_weights_only = True,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, y=train_targets, validation_split=0.2, batch_size=32, epochs=20, callbacks=[mcp_cb, rlr_cb, ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2083bed-7a88-4cf9-81a0-8b8ea4dac1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_targets, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b57658-cbe2-465f-ae67-6ca93e62374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_history(history):\n",
    "    plt.plot(history.history['acc'], label='train')\n",
    "    plt.plot(history.history['val_acc'], label='validation')\n",
    "    plt.legend()\n",
    "    \n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d41b2d-2e0d-4119-9df4-68d3cc88ae58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce9ef8-89da-4ea9-9faf-29d92d1d94cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81049b6-1842-45b0-84e5-b946bbcb5b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674fb2d-4d26-4fa9-86bc-b0fce26a0a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704502fd-3206-4c20-9542-14f28839ade1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
